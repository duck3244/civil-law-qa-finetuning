# ğŸ›ï¸ ë¯¼ë²• QA Fine-tuning í”„ë¡œì íŠ¸

ëŒ€í•œë¯¼êµ­ ë¯¼ë²• ì „ë¬¸ê°€ ëª¨ë¸ì„ ìœ„í•œ Llama 1B Fine-tuning í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ë¯¼ë²• QA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ Llama 1B ëª¨ë¸ì„ fine-tuningí•˜ì—¬ ë¯¼ë²• ì „ë¬¸ ìƒë‹´ì´ ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- **ì „ë¬¸ ë¶„ì•¼**: ì „ì„¸ì‚¬ê¸°, ë¶€ë™ì‚°ë¬¼ê¶Œ ë“± ë¯¼ë²• ì „ ë¶„ì•¼
- **íš¨ìœ¨ì  í›ˆë ¨**: LoRAë¥¼ í™œìš©í•œ parameter-efficient fine-tuning
- **ë©”ëª¨ë¦¬ ìµœì í™”**: 4bit ì–‘ìí™”, gradient checkpointing ë“±
- **ì„±ëŠ¥ í–¥ìƒ**: NEFTune, Liger Kernel ë“± ìµœì‹  ê¸°ë²• ì ìš©

## ğŸ—‚ï¸ íŒŒì¼ êµ¬ì¡°

```
â”œâ”€â”€ main.py                  # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ data_loader.py          # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
â”œâ”€â”€ data_formatter.py       # ë°ì´í„° í˜•ì‹ ë³€í™˜
â”œâ”€â”€ model_setup.py          # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •
â”œâ”€â”€ trainer_config.py       # í›ˆë ¨ ì„¤ì • ë° SFTTrainer
â”œâ”€â”€ inference_engine.py     # ì¶”ë¡  ë° í…ŒìŠ¤íŠ¸ ì—”ì§„
â”œâ”€â”€ requirements.txt        # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
â”œâ”€â”€ README.md              # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
â””â”€â”€ civil_law_qa_dataset.csv # ë¯¼ë²• QA ë°ì´í„°ì…‹
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd civil-law-qa-finetuning

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ë°ì´í„° ì¤€ë¹„

`civil_law_qa_dataset.csv` íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ë°°ì¹˜í•©ë‹ˆë‹¤.

### 3. ëª¨ë¸ í›ˆë ¨

```bash
# ê¸°ë³¸ í›ˆë ¨
python main.py --mode train

# ê³ í’ˆì§ˆ í›ˆë ¨ (ë” ë§ì€ ì—í¬í¬)
python main.py --mode train --preset quality --epochs 6

# íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ í›ˆë ¨
python main.py --mode train --categories ì „ì„¸ì‚¬ê¸° ë¶€ë™ì‚°ë¬¼ê¶Œ
```

### 4. ëª¨ë¸ ì‚¬ìš©

```bash
# ëŒ€í™”í˜• ëª¨ë“œ
python main.py --mode interactive

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ
python main.py --mode test
```

## ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´

### êµ¬ì¡°
- **ì´ 60ê°œ** ê³ í’ˆì§ˆ ë¯¼ë²• QA ìŒ
- **2ê°œ ì¹´í…Œê³ ë¦¬**: ì „ì„¸ì‚¬ê¸°(32ê°œ), ë¶€ë™ì‚°ë¬¼ê¶Œ(28ê°œ)
- **3ê°œ ë‚œì´ë„**: ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰

### í˜•ì‹
```csv
question,answer,category,difficulty
"ì§ˆë¬¸ ë‚´ìš©","ë‹µë³€ ë‚´ìš©","ì¹´í…Œê³ ë¦¬","ë‚œì´ë„"
```

## âš™ï¸ í›ˆë ¨ ì„¤ì •

### í”„ë¦¬ì…‹ ì˜µì…˜

| í”„ë¦¬ì…‹ | ì—í¬í¬ | í•™ìŠµë¥  | ë°°ì¹˜í¬ê¸° | ì„¤ëª… |
|--------|--------|--------|----------|------|
| `fast` | 2 | 2e-4 | 4 | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© |
| `balanced` | 4 | 1e-4 | 2 | ê· í˜•ì¡íŒ ì„¤ì • (ê¸°ë³¸) |
| `quality` | 6 | 5e-5 | 1 | ê³ í’ˆì§ˆ ê²°ê³¼ |
| `memory_efficient` | 3 | 1e-4 | 1 | ë©”ëª¨ë¦¬ ì ˆì•½ |

### ì»¤ìŠ¤í„°ë§ˆì´ì§•

```bash
# ì—í¬í¬ ìˆ˜ ë³€ê²½
python main.py --mode train --epochs 8

# í•™ìŠµë¥  ë³€ê²½
python main.py --mode train --learning_rate 5e-5

# ë°°ì¹˜ í¬ê¸° ë³€ê²½
python main.py --mode train --batch_size 4
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥

### 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ (`data_loader.py`)
- CSV íŒŒì¼ ìë™ ë¡œë”© (ë‹¤ì–‘í•œ ì¸ì½”ë”© ì§€ì›)
- ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
- ì¹´í…Œê³ ë¦¬ë³„/ë‚œì´ë„ë³„ í•„í„°ë§
- í†µê³„ ì •ë³´ ìë™ ìƒì„±

### 2. ë°ì´í„° í˜•ì‹ ë³€í™˜ (`data_formatter.py`)
- Conversational í˜•ì‹ ë³€í™˜ (ì±„íŒ… ëª¨ë¸ìš©)
- Instruction í˜•ì‹ ë³€í™˜ (prompt-completion)
- ì¹´í…Œê³ ë¦¬ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±
- í›ˆë ¨/ê²€ì¦ ë°ì´í„° ê· ë“± ë¶„í• 

### 3. ëª¨ë¸ ì„¤ì • (`model_setup.py`)
- ìë™ ëª¨ë¸ ë¡œë”© (4bit/8bit ì–‘ìí™” ì§€ì›)
- LoRA ì„¤ì • ë° ì ìš©
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- ëª¨ë¸ ì •ë³´ ì €ì¥

### 4. í›ˆë ¨ ê´€ë¦¬ (`trainer_config.py`)
- SFTTrainer ìë™ ì„¤ì •
- ë‹¤ì–‘í•œ í”„ë¦¬ì…‹ ì œê³µ
- í›ˆë ¨ ì‹œê°„ ì¶”ì •
- í›ˆë ¨ ì´ë ¥ ê´€ë¦¬

### 5. ì¶”ë¡  ì—”ì§„ (`inference_engine.py`)
- ëŒ€í™”í˜• ì±„íŒ… ëª¨ë“œ
- ë°°ì¹˜ ì¶”ë¡  ì§€ì›
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- ìë™ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

## ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ

### í›ˆë ¨ ì˜ˆì‹œ

```python
from data_loader import CivilLawDataLoader
from data_formatter import DataFormatter
from model_setup import ModelManager
from trainer_config import TrainerManager

# ë°ì´í„° ë¡œë”©
loader = CivilLawDataLoader("civil_law_qa_dataset.csv")
df = loader.load_dataset()
df = loader.preprocess_data()

# ë°ì´í„° ë³€í™˜
formatter = DataFormatter()
train_df, eval_df = formatter.stratified_split_by_category(df)
train_dataset = formatter.to_conversational_format(train_df)
eval_dataset = formatter.to_conversational_format(eval_df)

# ëª¨ë¸ ì„¤ì •
model_manager = ModelManager("meta-llama/Llama-3.2-1B")
model, tokenizer = model_manager.load_model_and_tokenizer()
model = model_manager.apply_lora()

# í›ˆë ¨
trainer_manager = TrainerManager("./output")
training_args = trainer_manager.create_training_config_from_preset("balanced")
trainer = trainer_manager.create_trainer(
    model=model,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer
)
trainer_manager.train()
trainer_manager.save_model()
```

### ì¶”ë¡  ì˜ˆì‹œ

```python
from inference_engine import InferenceEngine

# ëª¨ë¸ ë¡œë“œ
engine = InferenceEngine()
engine.load_finetuned_model("./output")

# ì§ˆë¬¸ ë‹µë³€
result = engine.generate_answer(
    "ì „ì„¸ë³´ì¦ê¸ˆì„ ëŒë ¤ë°›ì§€ ëª»í–ˆëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
    category="ì „ì„¸ì‚¬ê¸°"
)
print(result["answer"])

# ëŒ€í™”í˜• ëª¨ë“œ
engine.interactive_chat()
```

## ğŸ“ˆ ì„±ëŠ¥ ë° ìµœì í™”

### ë©”ëª¨ë¦¬ ìµœì í™”
- **4bit ì–‘ìí™”**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ~75% ê°ì†Œ
- **Gradient Checkpointing**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ê°€ ê°ì†Œ
- **LoRA**: í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ~1% ìˆ˜ì¤€

### ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•
- **NEFTune**: ë…¸ì´ì¦ˆ ì„ë² ë”©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
- **Liger Kernel**: 20% ì²˜ë¦¬ëŸ‰ ì¦ê°€, 60% ë©”ëª¨ë¦¬ ê°ì†Œ
- **Flash Attention 2**: ê¸´ ì‹œí€€ìŠ¤ íš¨ìœ¨ì  ì²˜ë¦¬

### ì˜ˆìƒ ì„±ëŠ¥

| GPU | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | í›ˆë ¨ ì‹œê°„ (60ìƒ˜í”Œ) | ì¶”ë¡  ì†ë„ |
|-----|---------------|-------------------|-----------|
| RTX 4090 | ~8GB | ~30ë¶„ | ~15 í† í°/ì´ˆ |
| RTX 3090 | ~10GB | ~45ë¶„ | ~12 í† í°/ì´ˆ |
| V100 | ~12GB | ~60ë¶„ | ~10 í† í°/ì´ˆ |
| T4 | ~8GB | ~120ë¶„ | ~5 í† í°/ì´ˆ |

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° í‰ê°€

### ìë™ í…ŒìŠ¤íŠ¸
```bash
# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python main.py --mode test

# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
python -c "
from inference_engine import InferenceEngine
engine = InferenceEngine()
engine.load_finetuned_model('./output')
engine.benchmark_generation_speed()
"
```

### í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬
1. **ì „ì„¸ì‚¬ê¸° ìƒë‹´**: ë³´ì¦ê¸ˆ ë°˜í™˜, ê³„ì•½ ê²€í† , ì‚¬ê¸° ì˜ˆë°©
2. **ë¶€ë™ì‚°ë¬¼ê¶Œ**: ì†Œìœ ê¶Œ, ë‹´ë³´ê¶Œ, ì·¨ë“ì‹œíš¨ ë“±
3. **ì¼ë°˜ ë¯¼ë²•**: ê³„ì•½ë²•, ë¶ˆë²•í–‰ìœ„ ë“±

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë©”ëª¨ë¦¬ íš¨ìœ¨ í”„ë¦¬ì…‹ ì‚¬ìš©
python main.py --mode train --preset memory_efficient

# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python main.py --mode train --batch_size 1
```

#### 2. í›ˆë ¨ ì†ë„ ëŠë¦¼
```bash
# ë¹ ë¥¸ í”„ë¦¬ì…‹ ì‚¬ìš©
python main.py --mode train --preset fast

# ì‹œí€€ìŠ¤ ê¸¸ì´ ê°ì†Œ
python main.py --mode train --max_length 512
```

#### 3. ëª¨ë¸ í’ˆì§ˆ ê°œì„ 
```bash
# ê³ í’ˆì§ˆ í”„ë¦¬ì…‹ ì‚¬ìš©
python main.py --mode train --preset quality --epochs 8

# í•™ìŠµë¥  ì¡°ì •
python main.py --mode train --learning_rate 5e-5
```

### ë””ë²„ê¹…

```python
# ë°ì´í„° ê²€ì¦
from data_loader import CivilLawDataLoader
loader = CivilLawDataLoader("civil_law_qa_dataset.csv")
df = loader.load_dataset()
print(loader.get_stats())

# ëª¨ë¸ ì •ë³´ í™•ì¸
from model_setup import ModelManager
manager = ModelManager()
model, tokenizer = manager.load_model_and_tokenizer()
print(manager.get_memory_usage())
```

## ğŸ“š ì¶”ê°€ ìë£Œ

### ê´€ë ¨ ê¸°ìˆ 
- [TRL (Transformer Reinforcement Learning)](https://github.com/huggingface/trl)
- [PEFT (Parameter Efficient Fine-tuning)](https://github.com/huggingface/peft)
- [Transformers](https://github.com/huggingface/transformers)
